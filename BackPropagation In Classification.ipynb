{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as ny # linear algebra\nimport pandas as ps # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-27T23:59:18.088179Z","iopub.execute_input":"2022-12-27T23:59:18.088738Z","iopub.status.idle":"2022-12-27T23:59:18.118767Z","shell.execute_reply.started":"2022-12-27T23:59:18.088630Z","shell.execute_reply":"2022-12-27T23:59:18.117331Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"dataset = ps.DataFrame([[8, 9, 4, 1], [5, 4, 7, 1], [5, 4, 3, 0], [3, 6, 2, 0]], columns = ['Cgpa', 'ProfileScore', 'InterviewScore', 'Selection'])\ndataset","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:59:18.124622Z","iopub.execute_input":"2022-12-27T23:59:18.125350Z","iopub.status.idle":"2022-12-27T23:59:18.154816Z","shell.execute_reply.started":"2022-12-27T23:59:18.125276Z","shell.execute_reply":"2022-12-27T23:59:18.153713Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   Cgpa  ProfileScore  InterviewScore  Selection\n0     8             9               4          1\n1     5             4               7          1\n2     5             4               3          0\n3     3             6               2          0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cgpa</th>\n      <th>ProfileScore</th>\n      <th>InterviewScore</th>\n      <th>Selection</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8</td>\n      <td>9</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>4</td>\n      <td>7</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>4</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>6</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def initializeParameters(layer_dims):\n  \n  ny.random.seed(3)\n  parameters = {}\n  layers = len(layer_dims)         \n\n  for layer in range(1, layers):\n\n    parameters['W' + str(layer)] = ny.ones((layer_dims[layer-1], layer_dims[layer]))*0.1\n    parameters['b' + str(layer)] = ny.zeros((layer_dims[layer], 1))\n      \n\n  return parameters","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:59:18.156738Z","iopub.execute_input":"2022-12-27T23:59:18.157028Z","iopub.status.idle":"2022-12-27T23:59:18.164335Z","shell.execute_reply.started":"2022-12-27T23:59:18.156993Z","shell.execute_reply":"2022-12-27T23:59:18.162470Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Utility Functions\ndef sigmoid(Z):\n  \n  A = 1/(1+ny.exp(-Z))\n\n  return A","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:59:18.166611Z","iopub.execute_input":"2022-12-27T23:59:18.167371Z","iopub.status.idle":"2022-12-27T23:59:18.177589Z","shell.execute_reply.started":"2022-12-27T23:59:18.167279Z","shell.execute_reply":"2022-12-27T23:59:18.176541Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def linearForward(A_prev, W, b):\n  \n  Z = ny.dot(W.T, A_prev) + b\n\n  A = sigmoid(Z)\n  \n  return A","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:59:18.180744Z","iopub.execute_input":"2022-12-27T23:59:18.181385Z","iopub.status.idle":"2022-12-27T23:59:18.192570Z","shell.execute_reply.started":"2022-12-27T23:59:18.181337Z","shell.execute_reply":"2022-12-27T23:59:18.190642Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# L-layer feed forward\n\ndef lLayerForward(x, parameters):\n\n  A = x\n  Layers = len(parameters) // 2                  # number of layers in the neural network\n  \n  for layer in range(1, Layers + 1):\n    Aprev = A \n    Wl = parameters['W' + str(layer)]\n    bl = parameters['b' + str(layer)]\n#     print(\"A\"+str(l-1)+\": \", A_prev)\n#     print(\"W\"+str(l)+\": \", Wl)\n#     print(\"b\"+str(l)+\": \", bl)\n#     print(\"--\"*20)\n\n    A = linearForward(Aprev, Wl, bl)\n#     print(\"A\"+str(l)+\": \", A)\n#     print(\"**\"*20)\n          \n  return A, Aprev","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:59:18.195195Z","iopub.execute_input":"2022-12-27T23:59:18.195590Z","iopub.status.idle":"2022-12-27T23:59:18.215576Z","shell.execute_reply.started":"2022-12-27T23:59:18.195559Z","shell.execute_reply":"2022-12-27T23:59:18.212702Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def update_parameters(parameters,y,y_hat,A1,X):\n  parameters['W2'][0][0] = parameters['W2'][0][0] + (0.0001 * (y - y_hat)*A1[0][0])\n  parameters['W2'][1][0] = parameters['W2'][1][0] + (0.0001 * (y - y_hat)*A1[1][0])\n  parameters['b2'][0][0] = parameters['W2'][1][0] + (0.0001 * (y - y_hat))\n\n  parameters['W1'][0][0] = parameters['W1'][0][0] + (0.0001 * (y - y_hat)*parameters['W2'][0][0]*A1[0][0]*(1-A1[0][0])*X[0][0])\n  parameters['W1'][0][1] = parameters['W1'][0][1] + (0.0001 * (y - y_hat)*parameters['W2'][0][0]*A1[0][0]*(1-A1[0][0])*X[1][0])\n  parameters['b1'][0][0] = parameters['b1'][0][0] + (0.0001 * (y - y_hat)*parameters['W2'][0][0]*A1[0][0]*(1-A1[0][0]))\n\n  parameters['W1'][1][0] = parameters['W1'][1][0] + (0.0001 * (y - y_hat)*parameters['W2'][1][0]*A1[1][0]*(1-A1[1][0])*X[0][0])\n  parameters['W1'][1][1] = parameters['W1'][1][1] + (0.0001 * (y - y_hat)*parameters['W2'][1][0]*A1[1][0]*(1-A1[1][0])*X[1][0])\n  parameters['b1'][1][0] = parameters['b1'][1][0] + (0.0001 * (y - y_hat)*parameters['W2'][1][0]*A1[1][0]*(1-A1[1][0]))","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:59:18.219117Z","iopub.execute_input":"2022-12-27T23:59:18.219671Z","iopub.status.idle":"2022-12-27T23:59:18.237261Z","shell.execute_reply.started":"2022-12-27T23:59:18.219630Z","shell.execute_reply":"2022-12-27T23:59:18.235156Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"X = dataset[['Cgpa', 'ProfileScore']].values[0].reshape(2,1) # Shape(no of features, no. of training example)\ny = dataset[['Selection']].values[0][0]\n\n# Parameter initialization\nparameters = initializeParameters([2,2,1])\n\ny_hat,A1 = lLayerForward(X,parameters)\ny_hat = y_hat[0][0]\n\nupdate_parameters(parameters,y,y_hat,A1,X)\n\nprint('Loss for this student - ',-y*ny.log(y_hat) - (1-y)*ny.log(1-y_hat))\n\nparameters","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:59:18.239448Z","iopub.execute_input":"2022-12-27T23:59:18.239878Z","iopub.status.idle":"2022-12-27T23:59:18.262121Z","shell.execute_reply.started":"2022-12-27T23:59:18.239832Z","shell.execute_reply":"2022-12-27T23:59:18.261332Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Loss for this student -  0.6121641007486958\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'W1': array([[0.10000479, 0.10000538],\n        [0.10000479, 0.10000538]]),\n 'b1': array([[5.98175564e-07],\n        [5.98175564e-07]]),\n 'W2': array([[0.10003871],\n        [0.10003871]]),\n 'b2': array([[0.10008449]])}"},"metadata":{}}]},{"cell_type":"code","source":"X = dataset[['Cgpa', 'ProfileScore']].values[1].reshape(2,1) # Shape(no of features, no. of training example)\ny = dataset[['Selection']].values[1][0]\n\ny_hat,A1 = lLayerForward(X,parameters)\ny_hat = y_hat[0][0]\n\nupdate_parameters(parameters,y,y_hat,A1,X)\n\nprint('Loss for this student - ',-y*ny.log(y_hat) - (1-y)*ny.log(1-y_hat))\n\nparameters","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:59:18.336503Z","iopub.execute_input":"2022-12-27T23:59:18.336953Z","iopub.status.idle":"2022-12-27T23:59:18.357244Z","shell.execute_reply.started":"2022-12-27T23:59:18.336920Z","shell.execute_reply":"2022-12-27T23:59:18.356289Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Loss for this student -  0.5793041781681331\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'W1': array([[0.10000931, 0.100009  ],\n        [0.10000931, 0.100009  ]]),\n 'b1': array([[1.50240050e-06],\n        [1.50239845e-06]]),\n 'W2': array([[0.10006997],\n        [0.10006997]]),\n 'b2': array([[0.10011394]])}"},"metadata":{}}]},{"cell_type":"code","source":"X = dataset[['Cgpa', 'ProfileScore']].values[2].reshape(2,1) # Shape(no of features, no. of training example)\ny = dataset[['Selection']].values[2][0]\n\ny_hat,A1 = lLayerForward(X,parameters)\ny_hat = y_hat[0][0]\n\nupdate_parameters(parameters,y,y_hat,A1,X)\n\nprint('Loss for this student - ',-y*ny.log(y_hat) - (1-y)*ny.log(1-y_hat))\n\nparameters","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:59:18.360523Z","iopub.execute_input":"2022-12-27T23:59:18.361059Z","iopub.status.idle":"2022-12-27T23:59:18.384763Z","shell.execute_reply.started":"2022-12-27T23:59:18.361024Z","shell.execute_reply":"2022-12-27T23:59:18.382255Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Loss for this student -  0.8216777921637785\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'W1': array([[0.10000355, 0.10000439],\n        [0.10000355, 0.10000439]]),\n 'b1': array([[3.50662990e-07],\n        [3.50659598e-07]]),\n 'W2': array([[0.10003014],\n        [0.10003014]]),\n 'b2': array([[0.09997411]])}"},"metadata":{}}]},{"cell_type":"code","source":"X = dataset[['Cgpa', 'ProfileScore']].values[3].reshape(2,1) # Shape(no of features, no. of training example)\ny = dataset[['Selection']].values[3][0]\n\ny_hat,A1 = lLayerForward(X,parameters)\ny_hat = y_hat[0][0]\n\nupdate_parameters(parameters,y,y_hat,A1,X)\n\nprint('Loss for this student - ',-y*ny.log(y_hat) - (1-y)*ny.log(1-y_hat))\n\nparameters","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:59:18.386277Z","iopub.execute_input":"2022-12-27T23:59:18.386692Z","iopub.status.idle":"2022-12-27T23:59:18.406191Z","shell.execute_reply.started":"2022-12-27T23:59:18.386653Z","shell.execute_reply":"2022-12-27T23:59:18.404508Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Loss for this student -  0.8215666059185625\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'W1': array([[0.10000009, 0.09999749],\n        [0.10000009, 0.09999749]]),\n 'b1': array([[-8.00541179e-07],\n        [-8.00540875e-07]]),\n 'W2': array([[0.0999903],\n        [0.0999903]]),\n 'b2': array([[0.09993428]])}"},"metadata":{}}]},{"cell_type":"code","source":"# epochs implementation\n\nparameters = initializeParameters([2,2,1])\nepochs = 50\n\nfor i in range(epochs):\n\n  Loss = []\n\n  for j in range(dataset.shape[0]):\n\n    X = dataset[['Cgpa', 'ProfileScore']].values[j].reshape(2,1) # Shape(no of features, no. of training example)\n    y = dataset[['Selection']].values[j][0]\n\n    # Parameter initialization\n\n\n    y_hat,A1 = lLayerForward(X, parameters)\n    y_hat = y_hat[0][0]\n\n    update_parameters(parameters,y,y_hat,A1,X)\n\n    Loss.append(-y*ny.log(y_hat) - (1-y)*ny.log(1-y_hat))\n\n  print('Epoch - ',i+1,'Loss - ',ny.array(Loss).mean())\n\nparameters","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:59:18.408660Z","iopub.execute_input":"2022-12-27T23:59:18.409098Z","iopub.status.idle":"2022-12-27T23:59:18.632055Z","shell.execute_reply.started":"2022-12-27T23:59:18.409065Z","shell.execute_reply":"2022-12-27T23:59:18.630916Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Epoch -  1 Loss -  0.7086781692497923\nEpoch -  2 Loss -  0.6975461225583588\nEpoch -  3 Loss -  0.6975446744202698\nEpoch -  4 Loss -  0.69754322679371\nEpoch -  5 Loss -  0.6975417796784794\nEpoch -  6 Loss -  0.6975403330743801\nEpoch -  7 Loss -  0.6975388869812127\nEpoch -  8 Loss -  0.6975374413987785\nEpoch -  9 Loss -  0.6975359963268787\nEpoch -  10 Loss -  0.6975345517653148\nEpoch -  11 Loss -  0.6975331077138881\nEpoch -  12 Loss -  0.6975316641724003\nEpoch -  13 Loss -  0.6975302211406531\nEpoch -  14 Loss -  0.6975287786184481\nEpoch -  15 Loss -  0.697527336605587\nEpoch -  16 Loss -  0.6975258951018719\nEpoch -  17 Loss -  0.6975244541071045\nEpoch -  18 Loss -  0.6975230136210873\nEpoch -  19 Loss -  0.6975215736436219\nEpoch -  20 Loss -  0.697520134174511\nEpoch -  21 Loss -  0.6975186952135567\nEpoch -  22 Loss -  0.6975172567605612\nEpoch -  23 Loss -  0.6975158188153275\nEpoch -  24 Loss -  0.6975143813776578\nEpoch -  25 Loss -  0.6975129444473548\nEpoch -  26 Loss -  0.6975115080242213\nEpoch -  27 Loss -  0.69751007210806\nEpoch -  28 Loss -  0.6975086366986739\nEpoch -  29 Loss -  0.6975072017958662\nEpoch -  30 Loss -  0.6975057673994398\nEpoch -  31 Loss -  0.6975043335091976\nEpoch -  32 Loss -  0.6975029001249432\nEpoch -  33 Loss -  0.6975014672464799\nEpoch -  34 Loss -  0.6975000348736109\nEpoch -  35 Loss -  0.6974986030061401\nEpoch -  36 Loss -  0.6974971716438706\nEpoch -  37 Loss -  0.6974957407866064\nEpoch -  38 Loss -  0.6974943104341511\nEpoch -  39 Loss -  0.6974928805863088\nEpoch -  40 Loss -  0.697491451242883\nEpoch -  41 Loss -  0.697490022403678\nEpoch -  42 Loss -  0.6974885940684977\nEpoch -  43 Loss -  0.6974871662371466\nEpoch -  44 Loss -  0.6974857389094287\nEpoch -  45 Loss -  0.6974843120851484\nEpoch -  46 Loss -  0.6974828857641101\nEpoch -  47 Loss -  0.6974814599461185\nEpoch -  48 Loss -  0.6974800346309779\nEpoch -  49 Loss -  0.6974786098184932\nEpoch -  50 Loss -  0.6974771855084692\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'W1': array([[0.09999243, 0.09986087],\n        [0.09999255, 0.09986096]]),\n 'b1': array([[-4.14210556e-05],\n        [-4.14167291e-05]]),\n 'W2': array([[0.09941566],\n        [0.09941575]]),\n 'b2': array([[0.09935976]])}"},"metadata":{}}]},{"cell_type":"code","source":"import tensorflow\nfrom tensorflow import keras\nfrom keras  import Sequential\nfrom keras.layers import Dense","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:59:18.634267Z","iopub.execute_input":"2022-12-27T23:59:18.634932Z","iopub.status.idle":"2022-12-27T23:59:25.650794Z","shell.execute_reply.started":"2022-12-27T23:59:18.634906Z","shell.execute_reply":"2022-12-27T23:59:25.649125Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(2, activation = 'sigmoid', input_dim = 2))\nmodel.add(Dense(1, activation = 'sigmoid'))\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:59:25.652997Z","iopub.execute_input":"2022-12-27T23:59:25.653774Z","iopub.status.idle":"2022-12-27T23:59:25.775188Z","shell.execute_reply.started":"2022-12-27T23:59:25.653735Z","shell.execute_reply":"2022-12-27T23:59:25.774285Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 2)                 6         \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 3         \n=================================================================\nTotal params: 9\nTrainable params: 9\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"},{"name":"stderr","text":"2022-12-27 23:59:25.691641: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n","output_type":"stream"}]},{"cell_type":"code","source":"model.get_weights()","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:59:25.776745Z","iopub.execute_input":"2022-12-27T23:59:25.777066Z","iopub.status.idle":"2022-12-27T23:59:25.786327Z","shell.execute_reply.started":"2022-12-27T23:59:25.777040Z","shell.execute_reply":"2022-12-27T23:59:25.785206Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"[array([[-0.5299088, -0.8004077],\n        [-1.0608083, -1.2019454]], dtype=float32),\n array([0., 0.], dtype=float32),\n array([[-1.3785155 ],\n        [-0.47647554]], dtype=float32),\n array([0.], dtype=float32)]"},"metadata":{}}]},{"cell_type":"code","source":"newweights = [ny.array([[0.1, 0.1],\n                        [0.1, 0.1]], dtype = ny.float32),\n             ny.array([0., 0.], dtype = ny.float32),\n             ny.array([[0.1],\n                      [0.1]], dtype = ny.float32),\n             ny.array([0.], dtype = ny.float32)]","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:59:25.787630Z","iopub.execute_input":"2022-12-27T23:59:25.787921Z","iopub.status.idle":"2022-12-27T23:59:25.798216Z","shell.execute_reply.started":"2022-12-27T23:59:25.787892Z","shell.execute_reply":"2022-12-27T23:59:25.796593Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"model.set_weights(newweights)","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:59:25.800348Z","iopub.execute_input":"2022-12-27T23:59:25.800804Z","iopub.status.idle":"2022-12-27T23:59:25.816065Z","shell.execute_reply.started":"2022-12-27T23:59:25.800761Z","shell.execute_reply":"2022-12-27T23:59:25.814943Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"optimizer  = keras.optimizers.Adam(learning_rate = 0.001)\nmodel.compile(loss = 'binary_crossentropy', optimizer = optimizer)\nmodel.fit(dataset.iloc[:, 0: 2].values, dataset['Selection'].values,epochs = 50, verbose = 1, batch_size = 1)","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:59:25.817292Z","iopub.execute_input":"2022-12-27T23:59:25.817713Z","iopub.status.idle":"2022-12-27T23:59:28.243204Z","shell.execute_reply.started":"2022-12-27T23:59:25.817688Z","shell.execute_reply":"2022-12-27T23:59:28.241915Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"2022-12-27 23:59:26.532922: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n4/4 [==============================] - 0s 3ms/step - loss: 0.6931\nEpoch 2/50\n4/4 [==============================] - 0s 2ms/step - loss: 0.6928\nEpoch 3/50\n4/4 [==============================] - 0s 3ms/step - loss: 0.6928\nEpoch 4/50\n4/4 [==============================] - 0s 2ms/step - loss: 0.6928\nEpoch 5/50\n4/4 [==============================] - 0s 2ms/step - loss: 0.6927\nEpoch 6/50\n4/4 [==============================] - 0s 3ms/step - loss: 0.6926\nEpoch 7/50\n4/4 [==============================] - 0s 2ms/step - loss: 0.6928\nEpoch 8/50\n4/4 [==============================] - 0s 3ms/step - loss: 0.6926\nEpoch 9/50\n4/4 [==============================] - 0s 4ms/step - loss: 0.6925\nEpoch 10/50\n4/4 [==============================] - 0s 4ms/step - loss: 0.6925\nEpoch 11/50\n4/4 [==============================] - 0s 4ms/step - loss: 0.6925\nEpoch 12/50\n4/4 [==============================] - 0s 3ms/step - loss: 0.6927\nEpoch 13/50\n4/4 [==============================] - 0s 2ms/step - loss: 0.6926\nEpoch 14/50\n4/4 [==============================] - 0s 2ms/step - loss: 0.6926\nEpoch 15/50\n4/4 [==============================] - 0s 2ms/step - loss: 0.6925\nEpoch 16/50\n4/4 [==============================] - 0s 3ms/step - loss: 0.6924\nEpoch 17/50\n4/4 [==============================] - 0s 2ms/step - loss: 0.6925\nEpoch 18/50\n4/4 [==============================] - 0s 1ms/step - loss: 0.6924\nEpoch 19/50\n4/4 [==============================] - 0s 2ms/step - loss: 0.6924\nEpoch 20/50\n4/4 [==============================] - 0s 2ms/step - loss: 0.6923\nEpoch 21/50\n4/4 [==============================] - 0s 2ms/step - loss: 0.6925\nEpoch 22/50\n4/4 [==============================] - 0s 2ms/step - loss: 0.6924\nEpoch 23/50\n4/4 [==============================] - 0s 2ms/step - loss: 0.6923\nEpoch 24/50\n4/4 [==============================] - 0s 3ms/step - loss: 0.6923\nEpoch 25/50\n4/4 [==============================] - 0s 3ms/step - loss: 0.6923\nEpoch 26/50\n4/4 [==============================] - 0s 2ms/step - loss: 0.6923\nEpoch 27/50\n4/4 [==============================] - 0s 1ms/step - loss: 0.6923\nEpoch 28/50\n4/4 [==============================] - 0s 2ms/step - loss: 0.6922\nEpoch 29/50\n4/4 [==============================] - 0s 1ms/step - loss: 0.6924\nEpoch 30/50\n4/4 [==============================] - 0s 2ms/step - loss: 0.6922\nEpoch 31/50\n4/4 [==============================] - 0s 2ms/step - loss: 0.6921\nEpoch 32/50\n4/4 [==============================] - 0s 2ms/step - loss: 0.6922\nEpoch 33/50\n4/4 [==============================] - 0s 2ms/step - loss: 0.6922\nEpoch 34/50\n4/4 [==============================] - 0s 1ms/step - loss: 0.6921\nEpoch 35/50\n4/4 [==============================] - 0s 2ms/step - loss: 0.6922\nEpoch 36/50\n4/4 [==============================] - 0s 2ms/step - loss: 0.6921\nEpoch 37/50\n4/4 [==============================] - 0s 2ms/step - loss: 0.6922\nEpoch 38/50\n4/4 [==============================] - 0s 2ms/step - loss: 0.6920\nEpoch 39/50\n4/4 [==============================] - 0s 1ms/step - loss: 0.6920\nEpoch 40/50\n4/4 [==============================] - 0s 2ms/step - loss: 0.6921\nEpoch 41/50\n4/4 [==============================] - 0s 2ms/step - loss: 0.6920\nEpoch 42/50\n4/4 [==============================] - 0s 2ms/step - loss: 0.6921\nEpoch 43/50\n4/4 [==============================] - 0s 2ms/step - loss: 0.6920\nEpoch 44/50\n4/4 [==============================] - 0s 2ms/step - loss: 0.6920\nEpoch 45/50\n4/4 [==============================] - 0s 1ms/step - loss: 0.6920\nEpoch 46/50\n4/4 [==============================] - 0s 2ms/step - loss: 0.6920\nEpoch 47/50\n4/4 [==============================] - 0s 2ms/step - loss: 0.6920\nEpoch 48/50\n4/4 [==============================] - 0s 3ms/step - loss: 0.6919\nEpoch 49/50\n4/4 [==============================] - 0s 3ms/step - loss: 0.6919\nEpoch 50/50\n4/4 [==============================] - 0s 2ms/step - loss: 0.6921\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f58937dc050>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}