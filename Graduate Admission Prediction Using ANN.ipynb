{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as ny # linear algebra\nimport pandas as ps # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-27T23:02:47.578041Z","iopub.execute_input":"2022-12-27T23:02:47.579396Z","iopub.status.idle":"2022-12-27T23:02:47.598397Z","shell.execute_reply.started":"2022-12-27T23:02:47.579279Z","shell.execute_reply":"2022-12-27T23:02:47.596345Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/graduate-admissions/Admission_Predict.csv\n/kaggle/input/graduate-admissions/Admission_Predict_Ver1.1.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset = ps.read_csv('/kaggle/input/graduate-admissions/Admission_Predict_Ver1.1.csv')\ndataset","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:02:47.606499Z","iopub.execute_input":"2022-12-27T23:02:47.607010Z","iopub.status.idle":"2022-12-27T23:02:47.645894Z","shell.execute_reply.started":"2022-12-27T23:02:47.606961Z","shell.execute_reply":"2022-12-27T23:02:47.644614Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"     Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n0             1        337          118                  4  4.5   4.5  9.65   \n1             2        324          107                  4  4.0   4.5  8.87   \n2             3        316          104                  3  3.0   3.5  8.00   \n3             4        322          110                  3  3.5   2.5  8.67   \n4             5        314          103                  2  2.0   3.0  8.21   \n..          ...        ...          ...                ...  ...   ...   ...   \n495         496        332          108                  5  4.5   4.0  9.02   \n496         497        337          117                  5  5.0   5.0  9.87   \n497         498        330          120                  5  4.5   5.0  9.56   \n498         499        312          103                  4  4.0   5.0  8.43   \n499         500        327          113                  4  4.5   4.5  9.04   \n\n     Research  Chance of Admit   \n0           1              0.92  \n1           1              0.76  \n2           1              0.72  \n3           1              0.80  \n4           0              0.65  \n..        ...               ...  \n495         1              0.87  \n496         1              0.96  \n497         1              0.93  \n498         0              0.73  \n499         0              0.84  \n\n[500 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Serial No.</th>\n      <th>GRE Score</th>\n      <th>TOEFL Score</th>\n      <th>University Rating</th>\n      <th>SOP</th>\n      <th>LOR</th>\n      <th>CGPA</th>\n      <th>Research</th>\n      <th>Chance of Admit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>337</td>\n      <td>118</td>\n      <td>4</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>9.65</td>\n      <td>1</td>\n      <td>0.92</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>324</td>\n      <td>107</td>\n      <td>4</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>8.87</td>\n      <td>1</td>\n      <td>0.76</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>316</td>\n      <td>104</td>\n      <td>3</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>8.00</td>\n      <td>1</td>\n      <td>0.72</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>322</td>\n      <td>110</td>\n      <td>3</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>8.67</td>\n      <td>1</td>\n      <td>0.80</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>314</td>\n      <td>103</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>8.21</td>\n      <td>0</td>\n      <td>0.65</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>496</td>\n      <td>332</td>\n      <td>108</td>\n      <td>5</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>9.02</td>\n      <td>1</td>\n      <td>0.87</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>497</td>\n      <td>337</td>\n      <td>117</td>\n      <td>5</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>9.87</td>\n      <td>1</td>\n      <td>0.96</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>498</td>\n      <td>330</td>\n      <td>120</td>\n      <td>5</td>\n      <td>4.5</td>\n      <td>5.0</td>\n      <td>9.56</td>\n      <td>1</td>\n      <td>0.93</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>499</td>\n      <td>312</td>\n      <td>103</td>\n      <td>4</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>8.43</td>\n      <td>0</td>\n      <td>0.73</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>500</td>\n      <td>327</td>\n      <td>113</td>\n      <td>4</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>9.04</td>\n      <td>0</td>\n      <td>0.84</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows × 9 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"dataset.shape","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:02:47.647730Z","iopub.execute_input":"2022-12-27T23:02:47.648997Z","iopub.status.idle":"2022-12-27T23:02:47.658507Z","shell.execute_reply.started":"2022-12-27T23:02:47.648947Z","shell.execute_reply":"2022-12-27T23:02:47.657056Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"(500, 9)"},"metadata":{}}]},{"cell_type":"code","source":"dataset.info()","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:02:47.661420Z","iopub.execute_input":"2022-12-27T23:02:47.661860Z","iopub.status.idle":"2022-12-27T23:02:47.681451Z","shell.execute_reply.started":"2022-12-27T23:02:47.661824Z","shell.execute_reply":"2022-12-27T23:02:47.680221Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 500 entries, 0 to 499\nData columns (total 9 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   Serial No.         500 non-null    int64  \n 1   GRE Score          500 non-null    int64  \n 2   TOEFL Score        500 non-null    int64  \n 3   University Rating  500 non-null    int64  \n 4   SOP                500 non-null    float64\n 5   LOR                500 non-null    float64\n 6   CGPA               500 non-null    float64\n 7   Research           500 non-null    int64  \n 8   Chance of Admit    500 non-null    float64\ndtypes: float64(4), int64(5)\nmemory usage: 35.3 KB\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset.duplicated().sum()","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:02:47.682986Z","iopub.execute_input":"2022-12-27T23:02:47.683354Z","iopub.status.idle":"2022-12-27T23:02:47.695248Z","shell.execute_reply.started":"2022-12-27T23:02:47.683320Z","shell.execute_reply":"2022-12-27T23:02:47.693848Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"dataset.drop(columns = ['Serial No.'], inplace = True)\ndataset","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:02:47.697540Z","iopub.execute_input":"2022-12-27T23:02:47.698656Z","iopub.status.idle":"2022-12-27T23:02:47.726141Z","shell.execute_reply.started":"2022-12-27T23:02:47.698611Z","shell.execute_reply":"2022-12-27T23:02:47.724737Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research  \\\n0          337          118                  4  4.5   4.5  9.65         1   \n1          324          107                  4  4.0   4.5  8.87         1   \n2          316          104                  3  3.0   3.5  8.00         1   \n3          322          110                  3  3.5   2.5  8.67         1   \n4          314          103                  2  2.0   3.0  8.21         0   \n..         ...          ...                ...  ...   ...   ...       ...   \n495        332          108                  5  4.5   4.0  9.02         1   \n496        337          117                  5  5.0   5.0  9.87         1   \n497        330          120                  5  4.5   5.0  9.56         1   \n498        312          103                  4  4.0   5.0  8.43         0   \n499        327          113                  4  4.5   4.5  9.04         0   \n\n     Chance of Admit   \n0                0.92  \n1                0.76  \n2                0.72  \n3                0.80  \n4                0.65  \n..                ...  \n495              0.87  \n496              0.96  \n497              0.93  \n498              0.73  \n499              0.84  \n\n[500 rows x 8 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GRE Score</th>\n      <th>TOEFL Score</th>\n      <th>University Rating</th>\n      <th>SOP</th>\n      <th>LOR</th>\n      <th>CGPA</th>\n      <th>Research</th>\n      <th>Chance of Admit</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>337</td>\n      <td>118</td>\n      <td>4</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>9.65</td>\n      <td>1</td>\n      <td>0.92</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>324</td>\n      <td>107</td>\n      <td>4</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>8.87</td>\n      <td>1</td>\n      <td>0.76</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>316</td>\n      <td>104</td>\n      <td>3</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>8.00</td>\n      <td>1</td>\n      <td>0.72</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>322</td>\n      <td>110</td>\n      <td>3</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>8.67</td>\n      <td>1</td>\n      <td>0.80</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>314</td>\n      <td>103</td>\n      <td>2</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>8.21</td>\n      <td>0</td>\n      <td>0.65</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>332</td>\n      <td>108</td>\n      <td>5</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>9.02</td>\n      <td>1</td>\n      <td>0.87</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>337</td>\n      <td>117</td>\n      <td>5</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>9.87</td>\n      <td>1</td>\n      <td>0.96</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>330</td>\n      <td>120</td>\n      <td>5</td>\n      <td>4.5</td>\n      <td>5.0</td>\n      <td>9.56</td>\n      <td>1</td>\n      <td>0.93</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>312</td>\n      <td>103</td>\n      <td>4</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>8.43</td>\n      <td>0</td>\n      <td>0.73</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>327</td>\n      <td>113</td>\n      <td>4</td>\n      <td>4.5</td>\n      <td>4.5</td>\n      <td>9.04</td>\n      <td>0</td>\n      <td>0.84</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows × 8 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"dataset.shape","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:02:47.728088Z","iopub.execute_input":"2022-12-27T23:02:47.728577Z","iopub.status.idle":"2022-12-27T23:02:47.737872Z","shell.execute_reply.started":"2022-12-27T23:02:47.728530Z","shell.execute_reply":"2022-12-27T23:02:47.736256Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(500, 8)"},"metadata":{}}]},{"cell_type":"code","source":"x = dataset.iloc[:, 0: -1]\ny = dataset.iloc[:, -1]\nx,y","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:02:47.739559Z","iopub.execute_input":"2022-12-27T23:02:47.740093Z","iopub.status.idle":"2022-12-27T23:02:47.761858Z","shell.execute_reply.started":"2022-12-27T23:02:47.740043Z","shell.execute_reply":"2022-12-27T23:02:47.760457Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n 0          337          118                  4  4.5   4.5  9.65         1\n 1          324          107                  4  4.0   4.5  8.87         1\n 2          316          104                  3  3.0   3.5  8.00         1\n 3          322          110                  3  3.5   2.5  8.67         1\n 4          314          103                  2  2.0   3.0  8.21         0\n ..         ...          ...                ...  ...   ...   ...       ...\n 495        332          108                  5  4.5   4.0  9.02         1\n 496        337          117                  5  5.0   5.0  9.87         1\n 497        330          120                  5  4.5   5.0  9.56         1\n 498        312          103                  4  4.0   5.0  8.43         0\n 499        327          113                  4  4.5   4.5  9.04         0\n \n [500 rows x 7 columns],\n 0      0.92\n 1      0.76\n 2      0.72\n 3      0.80\n 4      0.65\n        ... \n 495    0.87\n 496    0.96\n 497    0.93\n 498    0.73\n 499    0.84\n Name: Chance of Admit , Length: 500, dtype: float64)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nxtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size = 0.2, random_state = 1) ","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:02:47.763769Z","iopub.execute_input":"2022-12-27T23:02:47.764310Z","iopub.status.idle":"2022-12-27T23:02:48.348978Z","shell.execute_reply.started":"2022-12-27T23:02:47.764258Z","shell.execute_reply":"2022-12-27T23:02:48.347533Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"xtrain","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:02:48.350455Z","iopub.execute_input":"2022-12-27T23:02:48.351089Z","iopub.status.idle":"2022-12-27T23:02:48.373133Z","shell.execute_reply.started":"2022-12-27T23:02:48.351035Z","shell.execute_reply":"2022-12-27T23:02:48.371267Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"     GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  Research\n238        310          104                  3  2.0   3.5  8.37         0\n438        318          110                  1  2.5   3.5  8.54         1\n475        300          101                  3  3.5   2.5  7.88         0\n58         300           99                  1  3.0   2.0  6.80         1\n380        322          104                  3  3.5   4.0  8.84         1\n..         ...          ...                ...  ...   ...   ...       ...\n255        307          110                  4  4.0   4.5  8.37         0\n72         321          111                  5  5.0   5.0  9.45         1\n396        325          107                  3  3.0   3.5  9.11         1\n235        326          111                  5  4.5   4.0  9.23         1\n37         300          105                  1  1.0   2.0  7.80         0\n\n[400 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GRE Score</th>\n      <th>TOEFL Score</th>\n      <th>University Rating</th>\n      <th>SOP</th>\n      <th>LOR</th>\n      <th>CGPA</th>\n      <th>Research</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>238</th>\n      <td>310</td>\n      <td>104</td>\n      <td>3</td>\n      <td>2.0</td>\n      <td>3.5</td>\n      <td>8.37</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>438</th>\n      <td>318</td>\n      <td>110</td>\n      <td>1</td>\n      <td>2.5</td>\n      <td>3.5</td>\n      <td>8.54</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>475</th>\n      <td>300</td>\n      <td>101</td>\n      <td>3</td>\n      <td>3.5</td>\n      <td>2.5</td>\n      <td>7.88</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>300</td>\n      <td>99</td>\n      <td>1</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>6.80</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>380</th>\n      <td>322</td>\n      <td>104</td>\n      <td>3</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>8.84</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>255</th>\n      <td>307</td>\n      <td>110</td>\n      <td>4</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>8.37</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>321</td>\n      <td>111</td>\n      <td>5</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>9.45</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>396</th>\n      <td>325</td>\n      <td>107</td>\n      <td>3</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>9.11</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>235</th>\n      <td>326</td>\n      <td>111</td>\n      <td>5</td>\n      <td>4.5</td>\n      <td>4.0</td>\n      <td>9.23</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>300</td>\n      <td>105</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>7.80</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>400 rows × 7 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nxtrainscaled = scaler.fit_transform(xtrain)\nxtestscaled = scaler.transform(xtest)","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:02:48.374976Z","iopub.execute_input":"2022-12-27T23:02:48.375473Z","iopub.status.idle":"2022-12-27T23:02:48.397502Z","shell.execute_reply.started":"2022-12-27T23:02:48.375428Z","shell.execute_reply":"2022-12-27T23:02:48.396066Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"xtrainscaled","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:02:48.399627Z","iopub.execute_input":"2022-12-27T23:02:48.400429Z","iopub.status.idle":"2022-12-27T23:02:48.413806Z","shell.execute_reply.started":"2022-12-27T23:02:48.400376Z","shell.execute_reply":"2022-12-27T23:02:48.412373Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"array([[0.4       , 0.42857143, 0.5       , ..., 0.57142857, 0.50320513,\n        0.        ],\n       [0.56      , 0.64285714, 0.        , ..., 0.57142857, 0.55769231,\n        1.        ],\n       [0.2       , 0.32142857, 0.5       , ..., 0.28571429, 0.34615385,\n        0.        ],\n       ...,\n       [0.7       , 0.53571429, 0.5       , ..., 0.57142857, 0.74038462,\n        1.        ],\n       [0.72      , 0.67857143, 1.        , ..., 0.71428571, 0.77884615,\n        1.        ],\n       [0.2       , 0.46428571, 0.        , ..., 0.14285714, 0.32051282,\n        0.        ]])"},"metadata":{}}]},{"cell_type":"code","source":"import tensorflow\nfrom tensorflow import keras\nfrom keras import Sequential\nfrom keras.layers import Dense","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:02:48.419482Z","iopub.execute_input":"2022-12-27T23:02:48.419920Z","iopub.status.idle":"2022-12-27T23:02:50.458805Z","shell.execute_reply.started":"2022-12-27T23:02:48.419880Z","shell.execute_reply":"2022-12-27T23:02:50.457299Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(7, activation = 'relu', input_dim = 7))\nmodel.add(Dense(7, activation = 'relu', input_dim = 7))\nmodel.add(Dense(7, activation = 'relu', input_dim = 7))\nmodel.add(Dense(7, activation = 'relu', input_dim = 7))\nmodel.add(Dense(1, activation  = 'linear'))","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:02:50.460601Z","iopub.execute_input":"2022-12-27T23:02:50.461316Z","iopub.status.idle":"2022-12-27T23:02:50.533254Z","shell.execute_reply.started":"2022-12-27T23:02:50.461274Z","shell.execute_reply":"2022-12-27T23:02:50.532092Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"2022-12-27 23:02:50.471831: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n","output_type":"stream"}]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:02:50.534602Z","iopub.execute_input":"2022-12-27T23:02:50.535162Z","iopub.status.idle":"2022-12-27T23:02:50.541124Z","shell.execute_reply.started":"2022-12-27T23:02:50.535128Z","shell.execute_reply":"2022-12-27T23:02:50.540067Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 7)                 56        \n_________________________________________________________________\ndense_1 (Dense)              (None, 7)                 56        \n_________________________________________________________________\ndense_2 (Dense)              (None, 7)                 56        \n_________________________________________________________________\ndense_3 (Dense)              (None, 7)                 56        \n_________________________________________________________________\ndense_4 (Dense)              (None, 1)                 8         \n=================================================================\nTotal params: 232\nTrainable params: 232\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"model.compile(loss = 'mean_squared_error', optimizer = 'Adam', metrics= ['accuracy'])\ntraininglog = model.fit(xtrainscaled, ytrain, epochs = 100, validation_split = 0.2)","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:02:50.542629Z","iopub.execute_input":"2022-12-27T23:02:50.543328Z","iopub.status.idle":"2022-12-27T23:02:58.261402Z","shell.execute_reply.started":"2022-12-27T23:02:50.543291Z","shell.execute_reply":"2022-12-27T23:02:58.260089Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"2022-12-27 23:02:50.616964: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/100\n10/10 [==============================] - 1s 30ms/step - loss: 0.1814 - accuracy: 0.0000e+00 - val_loss: 0.1300 - val_accuracy: 0.0000e+00\nEpoch 2/100\n10/10 [==============================] - 0s 8ms/step - loss: 0.0811 - accuracy: 0.0000e+00 - val_loss: 0.0459 - val_accuracy: 0.0000e+00\nEpoch 3/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0282 - accuracy: 0.0000e+00 - val_loss: 0.0189 - val_accuracy: 0.0000e+00\nEpoch 4/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0190 - accuracy: 0.0000e+00 - val_loss: 0.0202 - val_accuracy: 0.0000e+00\nEpoch 5/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0190 - accuracy: 0.0000e+00 - val_loss: 0.0171 - val_accuracy: 0.0000e+00\nEpoch 6/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0158 - accuracy: 0.0000e+00 - val_loss: 0.0145 - val_accuracy: 0.0000e+00\nEpoch 7/100\n10/10 [==============================] - 0s 8ms/step - loss: 0.0142 - accuracy: 0.0000e+00 - val_loss: 0.0136 - val_accuracy: 0.0000e+00\nEpoch 8/100\n10/10 [==============================] - 0s 8ms/step - loss: 0.0131 - accuracy: 0.0000e+00 - val_loss: 0.0124 - val_accuracy: 0.0000e+00\nEpoch 9/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0120 - accuracy: 0.0000e+00 - val_loss: 0.0115 - val_accuracy: 0.0000e+00\nEpoch 10/100\n10/10 [==============================] - 0s 14ms/step - loss: 0.0113 - accuracy: 0.0000e+00 - val_loss: 0.0109 - val_accuracy: 0.0000e+00\nEpoch 11/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0106 - accuracy: 0.0000e+00 - val_loss: 0.0103 - val_accuracy: 0.0000e+00\nEpoch 12/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0100 - accuracy: 0.0000e+00 - val_loss: 0.0099 - val_accuracy: 0.0000e+00\nEpoch 13/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0095 - accuracy: 0.0000e+00 - val_loss: 0.0095 - val_accuracy: 0.0000e+00\nEpoch 14/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0091 - accuracy: 0.0000e+00 - val_loss: 0.0092 - val_accuracy: 0.0000e+00\nEpoch 15/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0088 - accuracy: 0.0000e+00 - val_loss: 0.0089 - val_accuracy: 0.0000e+00\nEpoch 16/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0085 - accuracy: 0.0000e+00 - val_loss: 0.0086 - val_accuracy: 0.0000e+00\nEpoch 17/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0082 - accuracy: 0.0000e+00 - val_loss: 0.0083 - val_accuracy: 0.0000e+00\nEpoch 18/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0079 - accuracy: 0.0000e+00 - val_loss: 0.0080 - val_accuracy: 0.0000e+00\nEpoch 19/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0076 - accuracy: 0.0000e+00 - val_loss: 0.0077 - val_accuracy: 0.0000e+00\nEpoch 20/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0074 - accuracy: 0.0000e+00 - val_loss: 0.0073 - val_accuracy: 0.0000e+00\nEpoch 21/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0071 - accuracy: 0.0000e+00 - val_loss: 0.0070 - val_accuracy: 0.0000e+00\nEpoch 22/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0069 - accuracy: 0.0000e+00 - val_loss: 0.0068 - val_accuracy: 0.0000e+00\nEpoch 23/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0067 - accuracy: 0.0000e+00 - val_loss: 0.0067 - val_accuracy: 0.0000e+00\nEpoch 24/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0065 - accuracy: 0.0000e+00 - val_loss: 0.0065 - val_accuracy: 0.0000e+00\nEpoch 25/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0064 - accuracy: 0.0000e+00 - val_loss: 0.0063 - val_accuracy: 0.0000e+00\nEpoch 26/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0062 - accuracy: 0.0000e+00 - val_loss: 0.0061 - val_accuracy: 0.0000e+00\nEpoch 27/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0061 - accuracy: 0.0000e+00 - val_loss: 0.0060 - val_accuracy: 0.0000e+00\nEpoch 28/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0060 - accuracy: 0.0000e+00 - val_loss: 0.0059 - val_accuracy: 0.0000e+00\nEpoch 29/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0059 - accuracy: 0.0000e+00 - val_loss: 0.0057 - val_accuracy: 0.0000e+00\nEpoch 30/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0057 - accuracy: 0.0000e+00 - val_loss: 0.0056 - val_accuracy: 0.0000e+00\nEpoch 31/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0056 - accuracy: 0.0000e+00 - val_loss: 0.0055 - val_accuracy: 0.0000e+00\nEpoch 32/100\n10/10 [==============================] - 0s 8ms/step - loss: 0.0055 - accuracy: 0.0000e+00 - val_loss: 0.0053 - val_accuracy: 0.0000e+00\nEpoch 33/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0055 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\nEpoch 34/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0054 - accuracy: 0.0000e+00 - val_loss: 0.0052 - val_accuracy: 0.0000e+00\nEpoch 35/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0053 - accuracy: 0.0000e+00 - val_loss: 0.0050 - val_accuracy: 0.0000e+00\nEpoch 36/100\n10/10 [==============================] - 0s 8ms/step - loss: 0.0052 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\nEpoch 37/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 0.0049 - val_accuracy: 0.0000e+00\nEpoch 38/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0051 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\nEpoch 39/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0050 - accuracy: 0.0000e+00 - val_loss: 0.0047 - val_accuracy: 0.0000e+00\nEpoch 40/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0049 - accuracy: 0.0000e+00 - val_loss: 0.0046 - val_accuracy: 0.0000e+00\nEpoch 41/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0045 - val_accuracy: 0.0000e+00\nEpoch 42/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\nEpoch 43/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0048 - accuracy: 0.0000e+00 - val_loss: 0.0044 - val_accuracy: 0.0000e+00\nEpoch 44/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0043 - val_accuracy: 0.0000e+00\nEpoch 45/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0047 - accuracy: 0.0000e+00 - val_loss: 0.0042 - val_accuracy: 0.0000e+00\nEpoch 46/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0046 - accuracy: 0.0000e+00 - val_loss: 0.0041 - val_accuracy: 0.0000e+00\nEpoch 47/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\nEpoch 48/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\nEpoch 49/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0045 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\nEpoch 50/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0040 - val_accuracy: 0.0000e+00\nEpoch 51/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0044 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 52/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\nEpoch 53/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0043 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 54/100\n10/10 [==============================] - 0s 8ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0039 - val_accuracy: 0.0000e+00\nEpoch 55/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 56/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 57/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 58/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 59/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0042 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 60/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 61/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0038 - val_accuracy: 0.0000e+00\nEpoch 62/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 63/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 64/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 65/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 66/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 67/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0041 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 68/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 69/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 70/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 71/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 72/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 73/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 74/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 75/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 76/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 77/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 78/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 79/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 80/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 81/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 82/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 83/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0037 - val_accuracy: 0.0000e+00\nEpoch 84/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 85/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 86/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 87/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 88/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0040 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 89/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 90/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 91/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 92/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 93/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 94/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 95/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 96/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 97/100\n10/10 [==============================] - 0s 8ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 98/100\n10/10 [==============================] - 0s 7ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0035 - val_accuracy: 0.0000e+00\nEpoch 99/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\nEpoch 100/100\n10/10 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.0000e+00 - val_loss: 0.0036 - val_accuracy: 0.0000e+00\n","output_type":"stream"}]},{"cell_type":"code","source":"ypredict = model.predict(xtestscaled)","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:02:58.262907Z","iopub.execute_input":"2022-12-27T23:02:58.263294Z","iopub.status.idle":"2022-12-27T23:02:58.425011Z","shell.execute_reply.started":"2022-12-27T23:02:58.263261Z","shell.execute_reply":"2022-12-27T23:02:58.423511Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import r2_score\nr2_score(ytest, ypredict)","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:02:58.426596Z","iopub.execute_input":"2022-12-27T23:02:58.427612Z","iopub.status.idle":"2022-12-27T23:02:58.436510Z","shell.execute_reply.started":"2022-12-27T23:02:58.427570Z","shell.execute_reply":"2022-12-27T23:02:58.434770Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"0.7937226715270163"},"metadata":{}}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(traininglog.history['loss'], color = 'black', label = 'Loss')\nplt.plot(traininglog.history['val_loss'], color = 'red', label = 'Val_Loss')","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:02:58.438406Z","iopub.execute_input":"2022-12-27T23:02:58.438826Z","iopub.status.idle":"2022-12-27T23:02:58.638089Z","shell.execute_reply.started":"2022-12-27T23:02:58.438788Z","shell.execute_reply":"2022-12-27T23:02:58.636464Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"[<matplotlib.lines.Line2D at 0x7f82405c8e10>]"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"plt.plot(traininglog.history['accuracy'], color = 'black', label = 'Accuracy')\nplt.plot(traininglog.history['val_accuracy'], color = 'red', label = 'Val_accruacy')","metadata":{"execution":{"iopub.status.busy":"2022-12-27T23:02:58.640223Z","iopub.execute_input":"2022-12-27T23:02:58.640760Z","iopub.status.idle":"2022-12-27T23:02:58.789566Z","shell.execute_reply.started":"2022-12-27T23:02:58.640710Z","shell.execute_reply":"2022-12-27T23:02:58.788181Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"[<matplotlib.lines.Line2D at 0x7f825246cc90>]"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}